{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_ai_utils import convert_audio_text, get_openai_response\n",
    "\n",
    "FILE_NAME = '53.mp3' # Change this to the name of your audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '53.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39m# Return the dictionary with timestamps and transcribed text\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text_time_stamp\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m text_time_stamp \u001b[39m=\u001b[39m transcribe_audio(FILE_NAME)\n",
      "\u001b[1;32m/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mTranscribes the given audio file into text by splitting it into chunks and processing them in parallel.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mdict: A dictionary mapping each chunk index to its transcribed text.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Load the audio file\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m sound \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39;49mfrom_mp3(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Split audio into chunks\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ahmedibrahim/Work/Sub_Gen/subtitle_gen.ipynb#W1sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m chunks \u001b[39m=\u001b[39m [sound[i:i \u001b[39m+\u001b[39m TIME_FOR_EACH_CHUNK] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sound), TIME_FOR_EACH_CHUNK)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydub/audio_segment.py:796\u001b[0m, in \u001b[0;36mAudioSegment.from_mp3\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_mp3\u001b[39m(\u001b[39mcls\u001b[39m, file, parameters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 796\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_file(file, \u001b[39m'\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m'\u001b[39;49m, parameters\u001b[39m=\u001b[39;49mparameters)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydub/audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m file, close_file \u001b[39m=\u001b[39m _fd_or_path_or_tempfile(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m, tempfile\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m:\n\u001b[1;32m    654\u001b[0m     \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pydub/utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     57\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fd, basestring):\n\u001b[0;32m---> 60\u001b[0m     fd \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fd, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m     61\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '53.mp3'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries to perform the task\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "CALLS = 50\n",
    "PERIOD = 60\n",
    "TIME_FOR_EACH_CHUNK = 10 * 1000  # TIMES 1000 because pydub works in milliseconds\n",
    "# Convert chunk to text\n",
    "LANGUAGE = 'ar'\n",
    "@sleep_and_retry\n",
    "@limits(calls=CALLS, period=PERIOD)\n",
    "def process_chunk(i, chunk):\n",
    "    \"\"\"\n",
    "    Processes an individual chunk of audio by exporting it, converting to text, and removing the file.\n",
    "    \n",
    "    Args:\n",
    "    i (int): The index of the chunk.\n",
    "    chunk (AudioSegment): The audio chunk to be processed.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the index of the chunk and the transcribed text.\n",
    "    \"\"\"\n",
    "    # Export chunk to WAV format\n",
    "    chunk.export(f'chunk{i}.wav', format='wav')\n",
    "\n",
    "    # Assuming convert_audio_text is a function that converts audio to text\n",
    "    text = convert_audio_text(f'chunk{i}.wav', language=LANGUAGE)\n",
    "    \n",
    "    # Remove the temporary chunk file\n",
    "    os.remove(f'chunk{i}.wav')\n",
    "\n",
    "    # Return the chunk index and associated text\n",
    "    return i, text\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"\n",
    "    Transcribes the given audio file into text by splitting it into chunks and processing them in parallel.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): The path of the audio file to be transcribed.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary mapping each chunk index to its transcribed text.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    sound = AudioSegment.from_mp3(file_path)\n",
    "\n",
    "    # Split audio into chunks\n",
    "    chunks = [sound[i:i + TIME_FOR_EACH_CHUNK] for i in range(0, len(sound), TIME_FOR_EACH_CHUNK)]\n",
    "\n",
    "    # Dictionary to store the text for each timestamp\n",
    "    text_time_stamp = {}\n",
    "\n",
    "    # Using ThreadPoolExecutor for parallel processing\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to process audio chunks\n",
    "        futures = [executor.submit(process_chunk, i, chunk) for i, chunk in enumerate(chunks)]\n",
    "        \n",
    "        # Record results in the text_time_stamp dictionary\n",
    "        for future in futures:\n",
    "            i, text = future.result()\n",
    "            text_time_stamp[i] = text\n",
    "\n",
    "    # Return the dictionary with timestamps and transcribed text\n",
    "    return text_time_stamp\n",
    "\n",
    "text_time_stamp = transcribe_audio(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the transcribed text dictionary to a string\n",
    "dict_message = str(text_time_stamp)\n",
    "\n",
    "# Assuming get_openai_response is a function that sends a request to OpenAI and gets a response\n",
    "response = get_openai_response(dict_message)\n",
    "print(response)\n",
    "\n",
    "# Extracting the dictionary part from the response\n",
    "dict_start = response.find('{')\n",
    "dict_end = response.find('}')\n",
    "response = response[dict_start:dict_end+1]\n",
    "\n",
    "# Cleaning up the response string by removing unnecessary characters\n",
    "response = response.replace('\\n', '')  # Removing new lines\n",
    "response = response.replace('  ', '')  # Removing extra spaces\n",
    "response = response.replace('\\\\n', '') # Removing escaped new lines\n",
    "response = response.replace('\\\\', '')  # Removing backslashes\n",
    "response = response.replace('\\'', '')  # Removing single quotes\n",
    "\n",
    "# Parsing the cleaned response string to reconstruct the dictionary\n",
    "response_2 = {}\n",
    "k = 0  # Index for the new dictionary\n",
    "for i in range(0, len(response)):\n",
    "    if response[i].isdigit() and response[i+1] == ':':\n",
    "        # Finding the next number followed by a colon to get the text in between\n",
    "        for j in range(i+2, len(response)):\n",
    "            if response[j].isdigit() and response[j+1] == ':':\n",
    "                response_2[k] = response[i+2:j-1].strip()  # Adding the text to the new dictionary\n",
    "                k += 1  # Incrementing the index\n",
    "                break\n",
    "\n",
    "# The final dictionary with cleaned and parsed response\n",
    "response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def format_srt_time(milliseconds):\n",
    "    \"\"\"\n",
    "    Converts milliseconds to SRT (SubRip Text) time format.\n",
    "\n",
    "    Args:\n",
    "    milliseconds (int): Time in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "    str: Time in SRT format (HH:MM:SS,mmm).\n",
    "    \"\"\"\n",
    "    seconds, milliseconds = divmod(milliseconds, 1000)\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    return f'{int(hours):02}:{int(minutes):02}:{int(seconds):02},{int(milliseconds):03}'\n",
    "\n",
    "def create_srt_file(text_time_stamp, file_name='transcription2.srt'):\n",
    "    \"\"\"\n",
    "    Creates an SRT file from a dictionary of timestamps and text.\n",
    "\n",
    "    Args:\n",
    "    text_time_stamp (dict): Dictionary with timestamps (as keys) and transcribed text (as values).\n",
    "    file_name (str): Name of the file to be created. Defaults to 'transcription2.srt'.\n",
    "    \"\"\"\n",
    "    with open(file_name, 'w') as file:\n",
    "        for i, text in text_time_stamp.items():\n",
    "            # Calculating the start and end times for each subtitle\n",
    "            start_time = i * TIME_FOR_EACH_CHUNK  # Assuming TWO_SECONDS_MS is the time for each chunk\n",
    "            end_time = (i + 1) * TIME_FOR_EACH_CHUNK\n",
    "\n",
    "            # Formatting times for SRT standard\n",
    "            start_time_srt = format_srt_time(start_time)\n",
    "            end_time_srt = format_srt_time(end_time)\n",
    "\n",
    "            # Writing the subtitle number, time range, and text to the file\n",
    "            file.write(f'{i+1}\\n')  # Subtitle number\n",
    "            file.write(f'{start_time_srt} --> {end_time_srt}\\n')  # Time range\n",
    "            file.write(f'{text}\\n\\n')  # Subtitle text\n",
    "\n",
    "# After your existing code to generate text_time_stamp dictionary\n",
    "create_srt_file(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
